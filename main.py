
# AI Backend Service - All 10 Algorithms Implementation
import numpy as np
import pandas as pd
import tensorflow as tf
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.tree import DecisionTreeClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, LSTM, Input
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from transformers import AutoTokenizer, AutoModel
import cv2
from flask import Flask, request, jsonify
from flask_cors import CORS
import joblib
import os
import base64
from PIL import Image
import io
import warnings
warnings.filterwarnings('ignore')

app = Flask(__name__)
CORS(app)

class MedicalAIAnalyzer:
    def __init__(self):
        self.models = {}
        self.scaler = StandardScaler()
        self.load_or_train_models()
    
    def load_or_train_models(self):
        """ุชุญููู ุฃู ุชุฏุฑูุจ ุฌููุน ุงูููุงุฐุฌ"""
        # 1. Logistic Regression
        self.models['logistic'] = LogisticRegression(random_state=42)
        
        # 2. Random Forest
        self.models['random_forest'] = RandomForestClassifier(n_estimators=100, random_state=42)
        
        # 3. SVM
        self.models['svm'] = SVC(kernel='rbf', probability=True, random_state=42)
        
        # 4. KNN
        self.models['knn'] = KNeighborsClassifier(n_neighbors=5)
        
        # 5. Naive Bayes
        self.models['naive_bayes'] = GaussianNB()
        
        # 6. Decision Tree
        self.models['decision_tree'] = DecisionTreeClassifier(random_state=42)
        
        # ุชุฏุฑูุจ ุงูููุงุฐุฌ ุงูุฃุณุงุณูุฉ ูุน ุจูุงูุงุช ููููุฉ
        self.train_basic_models()
        
        # 7-10. Neural Networks (ุณูุชู ุชุญููููุง ุนูุฏ ุงูุญุงุฌุฉ)
        self.build_neural_networks()
    
    def train_basic_models(self):
        """ุชุฏุฑูุจ ุงูููุงุฐุฌ ุงูุฃุณุงุณูุฉ"""
        # ุจูุงูุงุช ุทุจูุฉ ููููุฉ ููุชุฏุฑูุจ
        np.random.seed(42)
        X = np.random.randn(1000, 10)  # 10 ูุคุดุฑุงุช ุทุจูุฉ
        y = (X[:, 0] + X[:, 1] * 0.5 + np.random.randn(1000) * 0.1 > 0).astype(int)
        
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
        X_train_scaled = self.scaler.fit_transform(X_train)
        
        # ุชุฏุฑูุจ ูู ูููุฐุฌ
        for name, model in self.models.items():
            if name in ['logistic', 'random_forest', 'svm', 'knn', 'naive_bayes', 'decision_tree']:
                model.fit(X_train_scaled, y_train)
                print(f"โ ุชู ุชุฏุฑูุจ ูููุฐุฌ {name}")
    
    def build_neural_networks(self):
        """ุจูุงุก ุงูุดุจูุงุช ุงูุนุตุจูุฉ"""
        # 7. Basic Neural Network
        self.models['neural_network'] = Sequential([
            Dense(64, activation='relu', input_shape=(10,)),
            Dense(32, activation='relu'),
            Dense(16, activation='relu'),
            Dense(1, activation='sigmoid')
        ])
        self.models['neural_network'].compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
        
        # 8. CNN ููุตูุฑ ุงูุทุจูุฉ
        self.models['cnn'] = Sequential([
            Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),
            MaxPooling2D((2, 2)),
            Conv2D(64, (3, 3), activation='relu'),
            MaxPooling2D((2, 2)),
            Conv2D(128, (3, 3), activation='relu'),
            MaxPooling2D((2, 2)),
            Flatten(),
            Dense(512, activation='relu'),
            Dense(1, activation='sigmoid')
        ])
        self.models['cnn'].compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
        
        # 9. LSTM ููุจูุงูุงุช ุงูุฒูููุฉ
        self.models['lstm'] = Sequential([
            LSTM(50, return_sequences=True, input_shape=(30, 1)),
            LSTM(50, return_sequences=False),
            Dense(25),
            Dense(1, activation='sigmoid')
        ])
        self.models['lstm'].compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
        
        print("โ ุชู ุจูุงุก ุงูุดุจูุงุช ุงูุนุตุจูุฉ")
    
    def predict_disease_probability(self, lab_data, algorithm='ensemble'):
        """ุชููุน ุงุญุชูุงููุฉ ุงููุฑุถ"""
        try:
            if isinstance(lab_data, dict):
                # ุชุญููู ุงูุจูุงูุงุช ุฅูู array
                features = np.array(list(lab_data.values())).reshape(1, -1)
            else:
                features = np.array(lab_data).reshape(1, -1)
            
            features_scaled = self.scaler.transform(features)
            
            if algorithm == 'ensemble':
                # ุงุณุชุฎุฏุงู ุฌููุน ุงูููุงุฐุฌ ููุชุตููุช
                predictions = {}
                for name, model in self.models.items():
                    if name in ['logistic', 'random_forest', 'svm', 'knn', 'naive_bayes', 'decision_tree']:
                        if hasattr(model, 'predict_proba'):
                            pred = model.predict_proba(features_scaled)[0][1]
                        else:
                            pred = model.predict(features_scaled)[0]
                        predictions[name] = float(pred)
                
                # ุญุณุงุจ ุงููุชูุณุท ุงููุฑุฌุญ
                ensemble_pred = np.mean(list(predictions.values()))
                return {
                    'ensemble_probability': float(ensemble_pred),
                    'individual_predictions': predictions,
                    'confidence': self.calculate_confidence(predictions),
                    'recommendation': self.get_medical_recommendation(ensemble_pred)
                }
            else:
                # ุงุณุชุฎุฏุงู ุฎูุงุฑุฒููุฉ ูุญุฏุฏุฉ
                model = self.models.get(algorithm)
                if model and hasattr(model, 'predict_proba'):
                    pred = model.predict_proba(features_scaled)[0][1]
                    return {
                        'probability': float(pred),
                        'algorithm': algorithm,
                        'confidence': float(abs(pred - 0.5) * 2),
                        'recommendation': self.get_medical_recommendation(pred)
                    }
        except Exception as e:
            return {'error': f'ุฎุทุฃ ูู ุงูุชูุจุค: {str(e)}'}
    
    def analyze_medical_image(self, image_data):
        """ุชุญููู ุงูุตูุฑ ุงูุทุจูุฉ ุจุงุณุชุฎุฏุงู CNN"""
        try:
            # ุชุญููู base64 ุฅูู ุตูุฑุฉ
            image_bytes = base64.b64decode(image_data.split(',')[1])
            image = Image.open(io.BytesIO(image_bytes))
            image = image.resize((224, 224))
            image_array = np.array(image) / 255.0
            
            if len(image_array.shape) == 2:  # ุตูุฑุฉ ุฑูุงุฏูุฉ
                image_array = np.stack([image_array] * 3, axis=-1)
            
            image_array = np.expand_dims(image_array, axis=0)
            
            # ุงูุชูุจุค ุจุงุณุชุฎุฏุงู CNN
            prediction = self.models['cnn'].predict(image_array)[0][0]
            
            return {
                'abnormality_probability': float(prediction),
                'classification': 'ุบูุฑ ุทุจูุนู' if prediction > 0.5 else 'ุทุจูุนู',
                'confidence': float(abs(prediction - 0.5) * 2),
                'details': self.get_image_analysis_details(prediction)
            }
        except Exception as e:
            return {'error': f'ุฎุทุฃ ูู ุชุญููู ุงูุตูุฑุฉ: {str(e)}'}
    
    def analyze_time_series(self, time_data):
        """ุชุญููู ุงูุจูุงูุงุช ุงูุฒูููุฉ ุจุงุณุชุฎุฏุงู LSTM"""
        try:
            # ุชุญุถูุฑ ุงูุจูุงูุงุช ุงูุฒูููุฉ
            data = np.array(time_data).reshape(-1, 1)
            if len(data) < 30:
                # ุฅุถุงูุฉ padding ุฅุฐุง ูุงูุช ุงูุจูุงูุงุช ููููุฉ
                padding = np.zeros((30 - len(data), 1))
                data = np.vstack([padding, data])
            else:
                data = data[-30:]  # ุฃุฎุฐ ุขุฎุฑ 30 ูุฑุงุกุฉ
            
            data_scaled = (data - np.mean(data)) / (np.std(data) + 1e-8)
            data_input = np.expand_dims(data_scaled, axis=0)
            
            # ุงูุชูุจุค ุจุงุณุชุฎุฏุงู LSTM
            prediction = self.models['lstm'].predict(data_input)[0][0]
            
            return {
                'future_trend': float(prediction),
                'trend_direction': 'ุชุตุงุนุฏู' if prediction > 0.5 else 'ุชูุงุฒูู',
                'stability_score': self.calculate_stability(time_data),
                'recommendations': self.get_time_series_recommendations(prediction, time_data)
            }
        except Exception as e:
            return {'error': f'ุฎุทุฃ ูู ุชุญููู ุงูุจูุงูุงุช ุงูุฒูููุฉ: {str(e)}'}
    
    def detect_anomalies(self, lab_values):
        """ูุดู ุงูุดุฐูุฐ ูู ุงูุจูุงูุงุช ุงูุทุจูุฉ"""
        try:
            from sklearn.ensemble import IsolationForest
            
            data = np.array(lab_values).reshape(-1, 1)
            
            # ูููุฐุฌ ูุดู ุงูุดุฐูุฐ
            anomaly_detector = IsolationForest(contamination=0.1, random_state=42)
            anomaly_scores = anomaly_detector.fit_predict(data)
            anomaly_probs = anomaly_detector.score_samples(data)
            
            return {
                'anomaly_detected': bool(np.any(anomaly_scores == -1)),
                'anomaly_indices': np.where(anomaly_scores == -1)[0].tolist(),
                'anomaly_scores': anomaly_probs.tolist(),
                'severity': self.calculate_anomaly_severity(anomaly_probs),
                'recommendations': self.get_anomaly_recommendations(anomaly_scores)
            }
        except Exception as e:
            return {'error': f'ุฎุทุฃ ูู ูุดู ุงูุดุฐูุฐ: {str(e)}'}
    
    def calculate_confidence(self, predictions):
        """ุญุณุงุจ ูุณุชูู ุงูุซูุฉ"""
        values = list(predictions.values())
        std_dev = np.std(values)
        return float(max(0, 1 - std_dev * 2))  # ูููุง ูู ุงูุชุจุงููุ ุฒุงุฏุช ุงูุซูุฉ
    
    def get_medical_recommendation(self, probability):
        """ุชูุตูุงุช ุทุจูุฉ ุจูุงุก ุนูู ุงูุงุญุชูุงููุฉ"""
        if probability > 0.8:
            return {
                'urgency': 'ุนุงุฌู ุฌุฏุงู',
                'action': 'ูููุตุญ ุจูุฑุงุฌุนุฉ ุงูุทุจูุจ ููุฑุงู',
                'follow_up': 'ุฎูุงู 24 ุณุงุนุฉ'
            }
        elif probability > 0.6:
            return {
                'urgency': 'ูุชูุณุท',
                'action': 'ูููุตุญ ุจูุฑุงุฌุนุฉ ุงูุทุจูุจ ูุฑูุจุงู',
                'follow_up': 'ุฎูุงู ุฃุณุจูุน'
            }
        else:
            return {
                'urgency': 'ููุฎูุถ',
                'action': 'ูุชุงุจุนุฉ ุฏูุฑูุฉ',
                'follow_up': 'ุฎูุงู ุดูุฑ'
            }
    
    def get_image_analysis_details(self, probability):
        """ุชูุงุตูู ุชุญููู ุงูุตูุฑุฉ"""
        if probability > 0.7:
            return "ุชู ุงูุชุดุงู ุชุบูุฑุงุช ุบูุฑ ุทุจูุนูุฉ ูุงุถุญุฉ ูู ุงูุตูุฑุฉ"
        elif probability > 0.4:
            return "ุชุบูุฑุงุช ุทูููุฉ ูุฏ ุชุญุชุงุฌ ููุฑุงุฌุนุฉ ุทุจูุฉ"
        else:
            return "ูุง ุชูุฌุฏ ุชุบูุฑุงุช ูุงุถุญุฉ ูู ุงูุตูุฑุฉ"
    
    def calculate_stability(self, time_data):
        """ุญุณุงุจ ุงุณุชูุฑุงุฑ ุงูุจูุงูุงุช ุงูุฒูููุฉ"""
        if len(time_data) < 2:
            return 1.0
        
        changes = np.diff(time_data)
        stability = 1.0 / (1.0 + np.std(changes))
        return float(stability)
    
    def get_time_series_recommendations(self, prediction, time_data):
        """ุชูุตูุงุช ููุจูุงูุงุช ุงูุฒูููุฉ"""
        trend = np.polyfit(range(len(time_data)), time_data, 1)[0]
        
        if trend > 0.1:
            return "ุงููุชุงุฆุฌ ุชุธูุฑ ุงุชุฌุงูุงู ุชุตุงุนุฏูุงูุ ูููุตุญ ุจุงููุชุงุจุนุฉ ุงูุฏูููุฉ"
        elif trend < -0.1:
            return "ุงููุชุงุฆุฌ ุชุธูุฑ ุงุชุฌุงูุงู ุชูุงุฒููุงูุ ูุฏ ูุฏู ุนูู ุชุญุณู"
        else:
            return "ุงููุชุงุฆุฌ ูุณุชูุฑุฉุ ุงุณุชูุฑ ูู ุงูุฎุทุฉ ุงูุนูุงุฌูุฉ ุงูุญุงููุฉ"
    
    def calculate_anomaly_severity(self, scores):
        """ุญุณุงุจ ุดุฏุฉ ุงูุดุฐูุฐ"""
        min_score = np.min(scores)
        if min_score < -0.5:
            return "ุดุฐูุฐ ุดุฏูุฏ"
        elif min_score < -0.3:
            return "ุดุฐูุฐ ูุชูุณุท"
        else:
            return "ุดุฐูุฐ ุทููู"
    
    def get_anomaly_recommendations(self, anomaly_scores):
        """ุชูุตูุงุช ูุญุงูุงุช ุงูุดุฐูุฐ"""
        if np.any(anomaly_scores == -1):
            return "ุชู ุงูุชุดุงู ููู ุดุงุฐุฉุ ูููุตุญ ุจุฅุนุงุฏุฉ ุงููุญุต ูุงููุฑุงุฌุนุฉ ุงูุทุจูุฉ"
        else:
            return "ุฌููุน ุงูููู ุถูู ุงููุทุงู ุงููุชููุน"

# ุฅูุดุงุก ูุซูู ูู ุงููุญูู
analyzer = MedicalAIAnalyzer()

@app.route('/api/analyze/basic', methods=['POST'])
def analyze_basic():
    """ุชุญููู ุฃุณุงุณู ูููุคุดุฑุงุช ุงูุทุจูุฉ"""
    try:
        data = request.json
        lab_data = data.get('lab_values', {})
        algorithm = data.get('algorithm', 'ensemble')
        
        result = analyzer.predict_disease_probability(lab_data, algorithm)
        return jsonify({
            'success': True,
            'analysis': result,
            'timestamp': pd.Timestamp.now().isoformat()
        })
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500

@app.route('/api/analyze/image', methods=['POST'])
def analyze_image():
    """ุชุญููู ุงูุตูุฑ ุงูุทุจูุฉ"""
    try:
        data = request.json
        image_data = data.get('image')
        
        result = analyzer.analyze_medical_image(image_data)
        return jsonify({
            'success': True,
            'analysis': result,
            'timestamp': pd.Timestamp.now().isoformat()
        })
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500

@app.route('/api/analyze/timeseries', methods=['POST'])
def analyze_timeseries():
    """ุชุญููู ุงูุจูุงูุงุช ุงูุฒูููุฉ"""
    try:
        data = request.json
        time_data = data.get('time_values', [])
        
        result = analyzer.analyze_time_series(time_data)
        return jsonify({
            'success': True,
            'analysis': result,
            'timestamp': pd.Timestamp.now().isoformat()
        })
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500

@app.route('/api/analyze/anomaly', methods=['POST'])
def analyze_anomaly():
    """ูุดู ุงูุดุฐูุฐ"""
    try:
        data = request.json
        lab_values = data.get('values', [])
        
        result = analyzer.detect_anomalies(lab_values)
        return jsonify({
            'success': True,
            'analysis': result,
            'timestamp': pd.Timestamp.now().isoformat()
        })
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500

@app.route('/api/models/info', methods=['GET'])
def get_models_info():
    """ูุนูููุงุช ุนู ุงูููุงุฐุฌ ุงููุชุงุญุฉ"""
    models_info = {
        'logistic': 'ุงูุญุฏุงุฑ ููุฌุณุชู - ููุชุตููู ุงูุซูุงุฆู',
        'random_forest': 'ุงูุบุงุจุฉ ุงูุนุดูุงุฆูุฉ - ููุชุตููู ุงููุชูุฏู',
        'svm': 'ุขูุฉ ุงูุฏุนู ุงูุดุนุงุนู - ูููุตู ุงููุนูุฏ',
        'knn': 'ุฃูุฑุจ ุงูุฌูุฑุงู - ููุชุดุงุจู',
        'naive_bayes': 'ุจุงูุฒ ุงูุณุงุฐุฌ - ููุงุญุชูุงูุงุช',
        'decision_tree': 'ุดุฌุฑุฉ ุงููุฑุงุฑ - ููุชูุณูุฑ ุงููุงุถุญ',
        'neural_network': 'ุดุจูุฉ ุนุตุจูุฉ - ููุฃููุงุท ุงููุนูุฏุฉ',
        'cnn': 'ุดุจูุฉ ุชุทุจูููุฉ - ูุชุญููู ุงูุตูุฑ',
        'lstm': 'ุฐุงูุฑุฉ ูุตูุฑุฉ ุทูููุฉ - ููุจูุงูุงุช ุงูุฒูููุฉ',
        'anomaly_detection': 'ูุดู ุงูุดุฐูุฐ - ููุญุงูุงุช ุบูุฑ ุงูุนุงุฏูุฉ'
    }
    
    return jsonify({
        'success': True,
        'models': models_info,
        'total_models': len(models_info)
    })

if __name__ == '__main__':
    print("๐ ุจุฏุก ุชุดุบูู ุฎุฏูุฉ ุงูุฐูุงุก ุงูุงุตุทูุงุนู ุงูุทุจู...")
    print("โ ุชู ุชุญููู ุฌููุน ุงูุฎูุงุฑุฒููุงุช ุงูุนุดุฑุฉ")
    app.run(host='0.0.0.0', port=5000, debug=True)
